{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-qmy5cbwq\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 87726a08ed12e74ddc078ea877d9decf9a30cb8b\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting datasets[audio]\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from transformers==4.43.0.dev0)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.43.0.dev0)\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.43.0.dev0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (2024.5.15)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.43.0.dev0)\n",
      "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\python\\lib\\site-packages (from transformers==4.43.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Using cached torch-2.3.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\python\\lib\\site-packages (from datasets[audio]) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in d:\\python\\lib\\site-packages (from datasets[audio]) (0.6)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in d:\\python\\lib\\site-packages (from datasets[audio]) (2.2.2)\n",
      "Requirement already satisfied: xxhash in d:\\python\\lib\\site-packages (from datasets[audio]) (3.4.1)\n",
      "Collecting multiprocess (from datasets[audio])\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets[audio])\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting librosa (from datasets[audio])\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets[audio])\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\python\\lib\\site-packages (from aiohttp->datasets[audio]) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets[audio])\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\python\\lib\\site-packages (from aiohttp->datasets[audio]) (6.0.5)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets[audio])\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\lib\\site-packages (from requests->transformers==4.43.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\lib\\site-packages (from requests->transformers==4.43.0.dev0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\lib\\site-packages (from requests->transformers==4.43.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests->transformers==4.43.0.dev0) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\python\\lib\\site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: sympy in d:\\python\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in d:\\python\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Collecting jinja2 (from torch>=1.10.0->accelerate)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\python\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers==4.43.0.dev0) (0.4.6)\n",
      "Collecting audioread>=2.1.9 (from librosa->datasets[audio])\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\python\\lib\\site-packages (from librosa->datasets[audio]) (1.14.0)\n",
      "Collecting scikit-learn>=0.20.0 (from librosa->datasets[audio])\n",
      "  Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting joblib>=0.14 (from librosa->datasets[audio])\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from librosa->datasets[audio]) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa->datasets[audio])\n",
      "  Using cached numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting pooch>=1.1 (from librosa->datasets[audio])\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: soxr>=0.3.2 in d:\\python\\lib\\site-packages (from librosa->datasets[audio]) (0.3.7)\n",
      "Collecting lazy-loader>=0.1 (from librosa->datasets[audio])\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\python\\lib\\site-packages (from librosa->datasets[audio]) (1.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python\\lib\\site-packages (from pandas->datasets[audio]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python\\lib\\site-packages (from pandas->datasets[audio]) (2024.1)\n",
      "Requirement already satisfied: pycparser in d:\\python\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\python\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\python\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa->datasets[audio])\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\python\\lib\\site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in d:\\python\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.32.0-py3-none-any.whl (314 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "Using cached torch-2.3.1-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.43.0.dev0-py3-none-any.whl size=9342402 sha256=7661c799943c7cddd5d024a0eb09ba6b10bc09719ef62db09e82d9bc71b5c8ed\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-l4rfqpk8\\wheels\\54\\cb\\3f\\83103de5575c534436d6a4686686dead458238dfaf1147e98d\n",
      "Successfully built transformers\n",
      "Installing collected packages: yarl, MarkupSafe, llvmlite, lazy-loader, joblib, fsspec, frozenlist, filelock, dill, audioread, soundfile, scikit-learn, pooch, numba, multiprocess, jinja2, huggingface-hub, aiosignal, torch, tokenizers, librosa, aiohttp, transformers, accelerate, datasets\n",
      "Successfully installed MarkupSafe-2.1.5 accelerate-0.32.0 aiohttp-3.9.5 aiosignal-1.3.1 audioread-3.0.1 datasets-2.20.0 dill-0.3.8 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.23.4 jinja2-3.1.4 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 multiprocess-0.70.16 numba-0.60.0 pooch-1.8.2 scikit-learn-1.5.1 soundfile-0.12.1 tokenizers-0.19.1 torch-2.3.1 transformers-4.43.0.dev0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-req-build-qmy5cbwq'\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install --upgrade git+https://github.com/huggingface/transformers.git accelerate datasets[audio]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\python\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 435.7 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/1.8 MB 762.6 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.12.exe and pip3.exe are installed in 'd:\\Python\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Python\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--openai--whisper-large-v3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading readme: 100%|██████████| 480/480 [00:00<00:00, 480kB/s]\n",
      "Downloading data: 100%|██████████| 1.98M/1.98M [00:00<00:00, 2.57MB/s]\n",
      "Generating validation split: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ examples]\n",
      "d:\\Python\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5268\\555466692.py:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df = pd.read_csv('D:\\PythonProject File\\Final_Project\\English_enmotional_Test.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I recommend \n",
      "Sentiment: The comment is positive.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('D:\\PythonProject File\\Final_Project\\English_enmotional_Test.csv')\n",
    "\n",
    "# Get the column name\n",
    "english_columns = [col for col in df.columns if 'english' in col.lower()]\n",
    "if not english_columns:\n",
    "    english_column_name = input(\"Please enter the column name containing the English text: \")\n",
    "else:\n",
    "    english_column_name = english_columns[0]\n",
    "\n",
    "# Create the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyze the sentiment of the 4th row\n",
    "row_to_analyze = df.iloc[4][english_column_name]\n",
    "sentiment = sentiment_analyzer(row_to_analyze)[0]['label']\n",
    "\n",
    "if sentiment == 'POSITIVE':\n",
    "    sentiment_comment = \"The comment is positive.\"\n",
    "else:\n",
    "    sentiment_comment = \"The comment is negative.\"\n",
    "\n",
    "print(f\"Original text: {row_to_analyze}\")\n",
    "print(f\"Sentiment: {sentiment_comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5268\\1757429373.py:5: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df = pd.read_csv('D:\\PythonProject File\\Final_Project\\olist_order_reviews_dataset_English.csv')\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5268\\1757429373.py:34: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  df.to_csv('D:\\PythonProject File\\Final_Project\\English_enmotional_Test_with_sentiment.csv', index=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('D:\\PythonProject File\\Final_Project\\olist_order_reviews_dataset_English.csv')\n",
    "\n",
    "# Get the column name\n",
    "english_columns = [col for col in df.columns if 'english' in col.lower()]\n",
    "if not english_columns:\n",
    "    english_column_name = input(\"Please enter the column name containing the English text: \")\n",
    "else:\n",
    "    english_column_name = english_columns[0]\n",
    "\n",
    "# Create the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyze the sentiment of each row and save the result in the 'sentiment_column'\n",
    "for i, row in df.iterrows():\n",
    "    row_to_analyze = str(row[english_column_name])  # Convert the input to a string\n",
    "    if row_to_analyze != \"N/A\":\n",
    "        try:\n",
    "            sentiment = sentiment_analyzer(row_to_analyze)[0]['label']\n",
    "            if sentiment == 'POSITIVE':\n",
    "                sentiment_comment = \"positive\"\n",
    "            else:\n",
    "                sentiment_comment = \"negative\"\n",
    "        except ValueError:\n",
    "            sentiment_comment = \"N/A\"\n",
    "    else:\n",
    "        sentiment_comment = \"N/A\"\n",
    "    df.at[i, 'sentiment_column'] = sentiment_comment\n",
    "\n",
    "# Export the updated DataFrame to a new CSV file\n",
    "df.to_csv('D:\\PythonProject File\\Final_Project\\English_enmotional_Test_with_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
